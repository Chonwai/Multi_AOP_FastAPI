# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# CORS Configuration
# Comma-separated list or JSON array: ["http://localhost:3000", "https://example.com"]
# Use ["*"] to allow all origins (not recommended for production)
CORS_ORIGINS=["*"]

# Model Configuration
# Path relative to project root or absolute path
MODEL_PATH=predict/model/best_model_Oct13.pth
# Device for inference: cpu or cuda
DEVICE=cpu

# Sequence Processing Configuration
# Maximum sequence length (1-100)
SEQ_LENGTH=50
# Batch size for prediction (1-500)
BATCH_SIZE=16
# Maximum batch size for batch prediction endpoint (1-500)
MAX_BATCH_SIZE=100

# Logging Configuration
# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Environment
# Environment: development, production, testing
ENVIRONMENT=development

